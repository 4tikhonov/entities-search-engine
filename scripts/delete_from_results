#!/usr/bin/env coffee

# Pass the path of a results json file, supposedly made of an array of ids:
# all those ids documents will be deleted
[ resultPath ] = process.argv.slice(2)
{ host:elasticHost, index } = require('config').elastic

resolvePath = require './lib/resolve_path'
ids = require resolvePath(resultPath)
got = require 'got'
require 'colors'

type = resultPath.split('/').slice(-1)[0].split('.')[0]
console.log 'type'.blue, type
total = ids.length
console.log 'ids'.blue, total

# TODO: use the Bulk API
# https://www.elastic.co/guide/en/elasticsearch/reference/2.3/docs-bulk.html
deleteNextBulk = ->
  idsBatch = ids.splice(0, 1000)

  got.delete "http://localhost:9200/_bulk",
    body: idsBatch.map(metaDataLine).join '\n'
  .then ->
    console.log 'deleted'.green, idsBatch, "remaining: #{ids.length}".grey
    if ids.length > 0 then setTimeout deleteNextBulk, 200
  .catch (err)->
    # if 404, continue as the document might just
    # have been manully deleted earlier
    if err.statusCode is 404
      console.log '404'.yello, idsBatch[0..100], '[...]'
      setTimeout deleteNextBulk, 200
    else
      console.log 'err'.red, err

metaDataLine = (id)->
  "{\"delete\":{\"_index\":\"#{index}\",\"_type\":\"#{type}\",\"_id\":\"#{id}\"}}"

# let 5 seconds to kill the process if something is wrong
console.log 'starting in 5 seconds...'.grey
setTimeout deleteNextBulk, 5000
